{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "from os import getcwd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from factor_analysis import FactorAnalysis\n",
    "from factor_analysis.plotting import scree_plot, create_loadings_heatmaps\n",
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "\n",
    "filterwarnings(\"ignore\")\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "pd.set_option(\"display.precision\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Anwendungsbeispiel: California Housing Data (1990)\n",
    "\n",
    "Jede Beobachtung (Zeile) im Datensatz stellt eine sogenannte [*block group*](https://www.census.gov/programs-surveys/geography/about/glossary.html#par_textimage_4) in Kalifornien dar.\n",
    "\n",
    "Eine 'Block-Gruppe' ist eine statistische Aufteilung von des Volkszählungsamtes der USA,\n",
    "die zwischen 600 und 3000 Menschen umfassen sollten.\n",
    "Anstelle von Block-Gruppe werden wir hier meistens vereinfachend den Begriff *Bezirk* benutzen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Beschreibung der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = Path(getcwd(), \"data\", \"cal_housing.data\")\n",
    "X = pd.read_csv(path, header=0, sep=\",\")\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Insgesamt haben wir 20640 Beobachtungen (Bezirke) und 9 metrisch skalierte Merkmale.\n",
    "\n",
    "Da wir für die Faktoranalyse auch metrisch skalierte Merkmale benötigen, haben wir in diesem\n",
    "Bereich keine Probleme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Die Merkmale lassen sich also wie folgt beschreiben:\n",
    "\n",
    "- `longitude`: Längengrad eines Bezirks, Werte zwischen -124.35 und -114.31\n",
    "- `latitude`: Breitengrad eines Bezirks, Werte zwischen -32.54 und 41.95\n",
    "- `housing_median_age`: Median des Alters der Häuser in einem Bezirk, Werte zwischen 1 und 52 (Jahre)\n",
    "- `total_rooms`: Gesamtzahl der Räume eines Bezirks, Werte zwischen 2 und 39320\n",
    "- `total_bedrooms`: Gesamtzahl der Schlafzimmer eines Bezirks, Werte zwischen 1 und 6445\n",
    "- `population`: Einwohnerzahl eines Bezirks, Werte zwischen 3 und 35682\n",
    "- `households`: Gesamtzahl der Haushälte eines Bezirks, Werte zwischen 1 und 6082\n",
    "- `median_income`: Median des Einkommens der Einwohner, Werte zwischen 0.5 und 15\n",
    "- `median_house_value`: Median des Geldwertes der Häuser, Werte zwischen 15000 und 500 001 Dollar.\n",
    "\n",
    "Dabei fällt besonders der Wertebereich von `median_income` auf. Dies ist wahrscheinlich eine angepasste Skala und kein Einkommen in Dollar.\n",
    "\n",
    "Wenn wir noch einmal die Beschreibung eines Bezirks anschauen, dann sehen wir, dass in diesem Datensatz\n",
    "einige Ausreißer im Hinblick auf `population` vorliegen könnten. Denn ein Bezirk sollte hier zwischen 600 und 3000 Menschen umfassen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Fehlende Werte\n",
    "\n",
    "Der Datensatz enthält keine fehlenden Werte, wie wir in der `pd.info` Methode sehen können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Die Verteilung der Daten\n",
    "\n",
    "Nun schauen wir uns einige univariate und bivariate Plots der metrischen Merkmale an, um ein Gefühl für die Daten zu bekommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X.hist(figsize=(20, 15), bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Hier sehen wir, dass die vier Merkmale `total_rooms`, `total_bedrooms`, `population` und `households` eine relativ hohe\n",
    "Schiefe aufweisen.\n",
    "Ebenso hat `median_house_value` bei circa 500 000 eine hohe Dichte. Dies könnte dadurch begründet sein,\n",
    "dass der Wert 500 000 als obere Grenze benutzt wurde.\n",
    "\n",
    "\n",
    "### Ausreißeranalyse\n",
    "Bevor wir uns also bivariate Plots ansehen, werden wir mittels LocalOutlierFactor (LOF) versuchen, einige Ausreißer zu eliminieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = LocalOutlierFactor(n_neighbors=35).fit_predict(X)\n",
    "outliers = X[labels == -1]\n",
    "X = X[labels == 1]\n",
    "\n",
    "print(f\"Anzahl an mittels LOF als Ausreißer identifizierte Bezirke: {outliers.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wir können, sehen, dass der maximale Wert von `population` nun deutlich niedriger ist. Dennoch gibt es Bezirke mit sehr geringen Einwohnerzahlen (Minimum 3 Einwohner).\n",
    "\n",
    "Schauen wir uns nun die Verteilungen der Merkmale mittels eines Pairplots genauer an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(X, diag_kind=\"kde\", kind=\"scatter\", plot_kws={\"alpha\": 0.3})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In diesem Pairplot sind univariate Plots auf der Hauptdiagonalen und bivariate Plots auf den nicht-diagonalen Elementen.\n",
    "Hier fallen besonders drei Gruppen auf:\n",
    "\n",
    "##### Gruppe 1\n",
    "Die Merkmale `longitude` und `latitude` weisen eine relativ hohe negative Korrelation auf.\n",
    "\n",
    "\n",
    "##### Gruppe 2\n",
    "Die Merkmale `total_rooms`, `total_bedrooms`, `population` und `households` korrelieren hoch miteinander. Dies ist jedoch\n",
    "unter Beachtung der Bedeutung der Merkmale nicht überraschend, da eine hohe Anzahl an Menschen im Bezirk schließlich bedeuten muss, dass mehr\n",
    "Räume existieren und insgesamt die Zahl der Haushälte wohl höher sein muss.\n",
    "\n",
    "Das Merkmal `housing_median_age` könnte auch noch zu dieser Gruppe gezählt werden, da es eine leicht negative Korrelation zu diesen vier Merkmalen aufzeigt.\n",
    "\n",
    "\n",
    "##### Gruppe 3\n",
    "Die Merkmale `median_income` und `median_house_value` weisen ebenfalls eine sichtbare positive Korrelation auf, aber nicht so stark wie die in Gruppe 2.\n",
    "\n",
    "\n",
    "Diese drei Gruppen sind unten noch einmal in gesonderten Pairplots dargestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "group1 = [\"longitude\", \"latitude\"]\n",
    "group2 = [\"total_rooms\", \"total_bedrooms\", \"population\", \"households\"]\n",
    "group3 = [\"median_income\", \"median_house_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(X[group1], diag_kind=\"kde\", kind=\"scatter\", plot_kws={\"alpha\": 0.1}, size=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Hier sieht man, dass sich sehr viele Bezirke in zwei Regionen befinden. Dies erklärt die bimodale Struktur der beiden Merkmale `longitude` und `latitude`.\n",
    "Weiter unten befindet sich ein Scatter-Plot, der die geographische Verteilung der Bezirke noch genauer zeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(X[group2], diag_kind=\"kde\", kind=\"scatter\", plot_kws={\"alpha\": 0.3}, size=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(X[group3], diag_kind=\"kde\", kind=\"scatter\", plot_kws={\"alpha\": 0.3}, size=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Im letzten Pairplot fällt auch wieder die horizontale (bzw. vertikale) Linie bei `median_house_value = 500 000` auf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Geographische Verteilung der Häuserpreise\n",
    "\n",
    "Zudem können wir uns noch die graphische Verteilung der Häuserpreise ansehen.\n",
    "Unten dargestellt ist ein Scatter-Plot, der die Lage der Bezirke in Abhängigkeit\n",
    "des Medians der Häuserpreise berücksichtigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "sc = ax.scatter(x=\"longitude\", y=\"latitude\", c=\"median_house_value\", cmap=\"viridis\", data=X, alpha=0.4)\n",
    "plt.colorbar(sc, label=\"median_house_value\")\n",
    "\n",
    "cities = [\"Los Angeles\", \"San Francisco\"]\n",
    "xys = [(-118.243683, 34.052235), (-122.431297, 37.773972)]\n",
    "xys_text = [(-121, 33.5), (-123, 35.5)]\n",
    "for city, xy, xytext in zip(cities, xys, xys_text):\n",
    "    ax.annotate(city, xy=xy,  xycoords='data',\n",
    "            xytext=xytext,\n",
    "            arrowprops=dict(facecolor='red', shrink=0.05),\n",
    "            horizontalalignment='right', verticalalignment='top',\n",
    "            )\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "ax.set_xlabel(\"Längengrad\")\n",
    "ax.set_ylabel(\"Breitengrad\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Die Bezirke mit sehr teuren Häusern liegen am unteren Rand, also an der Küste. Zwei große Städte sind im Bild mit einem Pfeil markiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faktoranalyse Schritt 1: Geeignetheit der Daten untersuchen\n",
    "\n",
    "Zunächst müssen wir die Geeignetheit der Daten für die Faktoranalyse überprüfen.\n",
    "Dafür benutzen wir das Kaiser-Meyer-Olkin-Kriterium (KMO-Kriterium) für den kompletten Datensatz und das\n",
    "dazu verwandte Measure of sampling adequacy (MSA) für jedes einzelne Merkmal.\n",
    "\n",
    "Generell wollen wir, dass der KMO-Wert über 0.5 ist und der MSA-Wert für jede Variable ebenfalls 0.5 nicht\n",
    "unterschreitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "msa_values, kmo = calculate_kmo(X)\n",
    "print(f\"Der KMO-Wert beträgt {kmo:.4f}\\n\")\n",
    "msa_df = pd.DataFrame(msa_values.reshape(-1, 1), index=X.columns, columns=[\"MSA\"])\n",
    "print(msa_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der KMO-Wert ist über 0.6, was auf eine akzeptable Qualität hinweist. Dies ist jedoch kein idealer Wert.\n",
    "Außerdem ist der MSA-Wert für 4 Variablen unter 0.5, jedoch ist der Wert für die anderen Merkmale gut.\n",
    "\n",
    "Jetzt könnte man beispielweise die Merkmale mit einem MSA-Wert unter 0.5 entfernen. Für dieses Beispiel\n",
    "werden wir allerdings mit allen Variablen fortfahren.\n",
    "\n",
    "Man sollte sich zudem noch die Korrelationsmatrix direkt anschauen. Dies tun wir im Folgenden mit einer\n",
    "Heatmap, da sie sich sehr gut als visuelle Repräsentation eignet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "corr = X.corr().round(2)\n",
    "hm = sns.heatmap(data=corr, vmax=1, vmin=-1, cmap=\"RdBu_r\", annot=True)\n",
    "hm.set_xticklabels(X.columns, rotation=45)\n",
    "hm.set_yticklabels(X.columns)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wie wir schon im Pairplot gesehen haben, gibt es drei Gruppen von hoch korrelierten Merkmalen:\n",
    "Die vier Merkmale in der Mitte, sowie `housing_median_age` mit einer leicht negativen Korrelation zu diesen vier Merkmalen.\n",
    "Ebenso sind `Longitude` und `Latitude` negativ miteinander korreliert. Die Merkmale `median_income` und `median_house_value` sind positiv miteinander korreliert.\n",
    "\n",
    "Dies deutet schon darauf hin, dass eine 3-Faktorlösung wahrscheinlich eine gute Wahl von k sein könnte. Im Folgenden werden dies genauer betrachten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Faktoranalyse Schritt 2: Wahl der Faktorzahl $k$\n",
    "\n",
    "Um diese Frage zu beantworten, werden wir zunächst alle Faktoren mit der Hauptkomponentenmethode (Principal Component, PC)\n",
    "extrahieren und die Eigenwerte der Faktoren mithilfe eines 'Scree Plots' betrachten.\n",
    "\n",
    "Dann können wir die Faktoren behalten, die einen Eigenwert größer Eins (Kaiser-Kriterium) haben, oder anhand eines 'Knicks'\n",
    "im Plot eine geeignete Faktorzahl erkennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fa = FactorAnalysis(n_factors=X.shape[1], method=\"pc\").fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13, 8))\n",
    "scree_plot(fa.eigenvalues_, ax)\n",
    "ax.set_xlabel(\"Faktor\")\n",
    "ax.set_ylabel(\"Eigenwert\")\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier können wir sehen, dass die ersten drei Faktoren einen Eigenwert\n",
    "größer als Eins haben. Dies macht im Hinblick auf die Korrelationsmatrix,\n",
    "die wir vorhin gesehen haben, wegen den drei 'Boxen' auch Sinn. Nach\n",
    "dem Kaiser-Kriterium sollten wir also ein 3-Faktor-Modell benutzen.\n",
    "\n",
    "Der vierte Faktor ist jedoch nur minimal unter dem Eigenwert Eins, weshalb\n",
    "man diesen auch nicht direkt ausschließen sollte. Ein 'Knick' wäre bei\n",
    "$k = 5$ erkennbar.\n",
    "Wir werden also $k \\in [3, 4, 5]$ ausprobieren und den 'Besten' auswählen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Faktoranalyse Schritt 3: Extrahieren der Faktoren\n",
    "Jetzt führen wir die eigentliche Faktorextraktion durch.\n",
    "\n",
    "Dafür werden wir drei unterschiedliche Extraktionsmethoden miteinander vergleichen:\n",
    " - Hauptkomponentenmethode (engl. Principal Components (PC) Method)\n",
    " - Hauptachsen-Faktorisierung (engl. Principal Axis Factoring (PAF))\n",
    " - Iterierte Hauptachsen-Faktorisierung (engl. Iterated Principal Axis Factoring (Iterated PAF))\n",
    "\n",
    "Dabei ist die letzte Variante wohl die am häufigsten eingesetzte Methode (unter diesen drei)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "methods = [\n",
    "    (\"PC\", FactorAnalysis(method=\"pc\")),\n",
    "    (\"Nicht-iterierte PAF\", FactorAnalysis(method=\"paf\", max_iter=1)),\n",
    "    (\"Iterierte PAF\", FactorAnalysis(method=\"paf\", max_iter=50))\n",
    "]\n",
    "for n_factors in range(3, 6):\n",
    "    figsize = (10 + (1+n_factors)//2, 8)\n",
    "    create_loadings_heatmaps(X, methods, figsize, fa_params={\"n_factors\": n_factors})\n",
    "    plt.gcf().suptitle(f\"Ladungsmatrizen eines {n_factors}-Faktor-Modells\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Hier sehen wir in jeder Zeile die Ladungsmatrizen der drei unterschiedlichen Methoden als Heatmap dargestellt.\n",
    "Wir stellen fest, dass die 3-Faktorlösung tatsächlich im Hinblick auf eine einfache Struktur eine gute Lösung darstellt.\n",
    "Die 4-Faktorlösung könnte jedoch auch noch eine valide Lösung sein. Lediglich die 5-Faktorlösung ist problematisch,\n",
    "da kein Merkmal hoch (absoluter Wert größer 0.4) auf den fünften Faktor lädt.\n",
    "\n",
    "Ein Problem ist jedoch, dass das Merkmal `housing_median_age` nur bei der PC-Methode sehr hoch auf den vierten Faktor lädt\n",
    "und bei einer 3-Faktorlösung nur eine moderate Ladung auf den ersten Faktor hat.\n",
    "Dies deutet auf eine hohe spezifische Varianz hin, d.h. die Faktoren sind nicht gut in der Lage, die Varianz dieses Merkmals\n",
    "zu erklären.\n",
    "\n",
    "Wir werden also die 3-Faktorlösung genauer betrachten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fa_params = {\"n_factors\": 3}\n",
    "\n",
    "axes = create_loadings_heatmaps(X, methods, figsize=(10, 9), fa_params=fa_params, annotate=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wir können sehen, dass bei der PC-Methode die Ladungen generell höher ausfallen und dass der zweite Faktor ein unterschiedliches\n",
    "Vorzeichen besitzt, im Gegensatz zu den anderen beiden Methoden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Die iterierte und nicht-iterierte PAF-Methode sind sehr ähnlich zueinander. Jedoch ist die iterierte\n",
    "Variante oft in Hinblick auf die reproduzierte Korrelationsmatrix besser. Dies können wir anhand des\n",
    "*root mean squared error* (RMSE) untersuchen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for method, fa in methods:\n",
    "    rmse = fa.get_rmse()\n",
    "    print(f\"RMSE von {method}: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Der root mean squared error of residuals (RMSE) ist bei der iterierten PAF-Methode am geringsten,\n",
    "gefolgt von der nicht-iterativen Variante und der Hauptkomponentenmethode.\n",
    "\n",
    "Schauen wir uns nun noch die Kommunalitäten der Variablen an. Dies zeigt uns zum Beispiel die `print_summary` Methode an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Zusammenfassung der iterierten PAF-Methode\n",
    "methods[2][1].print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Die spezifische Varianz von `housing_median_age` ist mit einem Wert von 0.8980 sehr hoch.\n",
    "Das bedeutet, dass die Faktoren die Varianz dieses Merkmals gemeinsam nicht besonders gut erklären können.\n",
    "Dies spiegelt sich ebenfalls in den geringen Ladungen auf die drei Faktoren wider.\n",
    "Die spezifischen Varianzen bei den restlichen Merkmalen sind jedoch sehr niedrig,\n",
    "was ein gutes Zeichen für die Qualität der Faktorlösung ist.\n",
    "\n",
    "\n",
    "Da das Merkmal `housing_median_age` eine sehr hohe spezifische Varianz (geringe Kommunalität) aufweist\n",
    "können wir auch ein 3-Faktor-Modell ohne diesem Merkmal anschauen.\n",
    "Dieses kann den RMSE um knapp 44% reduzieren (im Vergleich sind die iterierten PAF-Methoden),\n",
    "weshalb wir dieses Merkmal für die weitere Analyse entfernen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_without_age = X.drop(columns=\"housing_median_age\", axis=1)\n",
    "fa_without_age = FactorAnalysis(n_factors=3).fit(X_without_age)\n",
    "perc = 1 - fa_without_age.get_rmse() / rmse\n",
    "print(f\"Der RMSE konnte durch Entfernen des Merkmals um {perc:.2%} reduziert werden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "Den Unterschied zwischen den Methoden im RMSE können wir auch noch grafisch analysieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(12, 6))\n",
    "fitted_methods = [\n",
    "    (\"PC\", FactorAnalysis(method=\"pc\", n_factors=3).fit(X)),\n",
    "    (\"Iterierte PAF\", FactorAnalysis(method=\"paf\", n_factors=3, max_iter=50).fit(X))\n",
    "]\n",
    "for ax, (method, fa) in zip(axes, fitted_methods):\n",
    "    R = fa.corr_\n",
    "    R_hat = fa.get_reprod_corr()\n",
    "    abs_residuals = np.abs(R - R_hat)\n",
    "    mask = np.triu(np.ones_like(R))\n",
    "    ax.set_title(f\"{method} (RMSE = {fa.get_rmse():.4f})\", fontsize=11)\n",
    "    s = sns.heatmap(abs_residuals.round(2), cmap=\"BuGn\", ax=ax, cbar=False, annot=True, square=True, mask=mask)\n",
    "    s.set_xticklabels(range(1, 10))\n",
    "    s.set_yticklabels(range(1, 10), rotation=0)\n",
    "fig.suptitle(\"Residualmatrizen von zwei Extraktionsmethoden mit k=3\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Bevor wir zur Faktorrotation und -interpretation kommen, werden wir noch die verschiedenen initialen Schätzungen der Kommunalitäten in der (iterierten) PAF-Methode vergleichen.\n",
    "Interessant könnte dabei sein, ob die Wahl der initialen Schätzung einen Einfluss auf die finalen Ladungen hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "paf_comparison_methods = [\n",
    "    (\"Nicht-iterierte PAF\", FactorAnalysis(method=\"paf\", max_iter=1)),\n",
    "    (\"PAF mit max_iter=3\", FactorAnalysis(method=\"paf\", max_iter=3)),\n",
    "    (\"Iterierte PAF\", FactorAnalysis(method=\"paf\", max_iter=50)),\n",
    "]\n",
    "figsize = (8, 6)\n",
    "initial_communality_estimates = {\n",
    "    \"smc\": \"Quadrierte multiple Korrelationen (SMC)\",\n",
    "    \"mac\": \"Maximale absolute Korrelationen (MAC)\",\n",
    "    \"ones\": \"Einsen\"\n",
    "}\n",
    "for init_comm in initial_communality_estimates:\n",
    "    print(f\"Initiale Schätzung: {initial_communality_estimates[init_comm]}\")\n",
    "    create_loadings_heatmaps(X, paf_comparison_methods, figsize, fa_params={\"n_factors\": 3, \"initial_comm\" : init_comm})\n",
    "    plt.show()\n",
    "    print(f\"Iterierte PAF hat {paf_comparison_methods[2][1].n_iter_} Iterationen benötigt.\")\n",
    "    for method, fa in paf_comparison_methods:\n",
    "        print(f\"RMSE von {method}: {fa.get_rmse():.4f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Wir können sehen, dass nur geringe Unterschiede zwischen den unterschiedlichen initialen Schätzungen\n",
    "in den Ladungen feststellbar sind. Nur in der nicht-iterierten Variante der PAF-Methode können wir einige\n",
    "Unterschiede, vor allem im zweiten Faktor feststellen. Beispielsweise hat der zweite Faktor hier ein unterschiedliches\n",
    "Vorzeichen, jedoch nur, wenn Einsen als Kommunalitätsschätzung benutzt wurden. In diesem\n",
    "Fall ist das Ergebnis identisch zur Hauptkomponentenmethode.\n",
    "\n",
    "Wir stellen fest, dass die iterierte Variante jedoch eine unterschiedliche Anzahl an Iterationen benötigt, bis\n",
    "das Konvergenzkriterium erreicht wird. Am langsamsten ist es auf diesem Datensatz im Falle von Einsen (10 Iterationen) und am schnellsten ist es\n",
    "bei den maximalen absoluten Korrelationen (MAC) (nur 3 Iterationen). Ist das Konvergenzkriterium erfüllt, sind die Ladungen jedoch\n",
    "bei allen drei initialen Schätzungen weitestgehend identisch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Faktoranalyse Schritt 4: Faktorrotation und -interpretation\n",
    "Jetzt rotieren wir die Ladungen mit der Varimax-Methode und versuchen, die Faktoren zu interpretieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "methods = [\n",
    "    (\"Unrotiert\", FactorAnalysis(method=\"paf\", rotation=None)),\n",
    "    (\"Varimax-Rotation\", FactorAnalysis(method=\"paf\", rotation=\"varimax\"))\n",
    "]\n",
    "fa_params = {\"n_factors\": 3}\n",
    "fig = create_loadings_heatmaps(X_without_age, methods, fa_params=fa_params)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Müssten wir die Faktoren interpretieren, könnte man sagen, dass\n",
    "- der erste Faktor die Größe des Bezirks widerspiegelt,\n",
    "- der zweite Faktor den Standort des Bezirks berücksichtigt und\n",
    "- der dritte Faktor den Wohlstand im Bezirk bezeichnet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Faktoranalyse Schritt 5: Die Faktorwerte bestimmen\n",
    "\n",
    "Als letzten Schritt können wir noch einen Blick auf die geschätzten Faktorwerte\n",
    "werfen. Wie hätte als der Bezirk $i$ die drei oben beschriebenen Faktoren bewertet?\n",
    "\n",
    "Die hier benutzte Methode zur Schätzung der Faktorwerte ist die *Regressionsmethode*,\n",
    "welche eine multivariate lineare Regression benutzt, um die Faktorwerte\n",
    "zu schätzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scores = FactorAnalysis(n_factors=3).fit_transform(X_without_age)\n",
    "scores = pd.DataFrame(scores, columns=[\"Größe\", \"Standort\", \"Wohlstand\"])\n",
    "scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scores.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Hier weisen die Faktorwerte keine Einheitsvarianz beziehungsweise Standardabweichung von eins auf, weil die PAF-Methode mit\n",
    "quadrierten multiplen Quadraten als initiale Schätzung verwendet wurde.\n",
    "\n",
    "Benutzt man jedoch die Hauptkomponentenmethode, so weisen die Faktorwerte eine\n",
    "Standardabweichung von Eins auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scores = FactorAnalysis(method=\"pc\", n_factors=3).fit_transform(X_without_age)\n",
    "scores.std(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
