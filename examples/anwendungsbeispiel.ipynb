{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "from os import getcwd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from factor_analysis import FactorAnalysis\n",
    "from factor_analysis.plotting import scree_plot, create_loadings_heatmaps, create_corr_heatmap\n",
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "\n",
    "filterwarnings(\"ignore\")\n",
    "np.set_printoptions(suppress=True, precision=8)\n",
    "pd.set_option(\"display.precision\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Anwendungsbeispiel: California Housing Data (1990)\n",
    "\n",
    "In der Datensatzbeschreibung heißt es:\n",
    "> This dataset appeared in a 1997 paper titled Sparse Spatial Autoregressions by Pace, R. Kelley and Ronald Barry, published in the Statistics and Probability Letters journal.\n",
    "> They built it using the 1990 California census data.\n",
    ">\n",
    "> It contains one row per census block group. A block group is the smallest geographical unit for which the U.S. Census Bureau publishes sample data\n",
    "> (a block group typically has a population of 600 to 3,000 people).\n",
    "\n",
    "Das bedeutet, dass jede Beobachtung eine sogenannte [*block group*](https://www.census.gov/programs-surveys/geography/about/glossary.html#par_textimage_4) angibt. Eine 'Block-Gruppe'\n",
    "ist eine statistische Aufteilung von des Volkszählungsamtes der USA, die zwischen 600 und 3000 Menschen umfassen sollten.\n",
    "\n",
    "Anstelle von Block-Gruppe werden wir hier meistens vereinfachend den Begriff Bezirk oder Gegend benutzen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Beschreibung der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = Path(getcwd(), \"data\", \"cal_housing.data\")\n",
    "X = pd.read_csv(path, header=0, sep=\",\")\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Insgesamt haben wir 20640 Beobachtungen (Bezirke) und 9 metrisch skalierte Merkmale. Also gibt es auch keine fehlende Werte,\n",
    "wie man im Output der `info` Methode sehen können.\n",
    "\n",
    "Für die Faktoranalyse benötigen wir metrisch skalierte Merkmale. Vorliegend sind alle neun Merkmale metrisch, weshalb wir in diesem\n",
    "Bereich keine Probleme haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Die Merkmale lassen sich also wie folgt beschreiben:\n",
    "\n",
    "- `longitude`: Längengrad eines Bezirks, Werte zwischen -124.35 und -114.31\n",
    "- `latitude`: Breitengrad eines Bezirks, Werte zwischen -32.54 und 41.95\n",
    "- `housing_median_age`: Median des Alters der Häuser in einem Bezirk, Werte zwischen 1 und 52 (Jahre)\n",
    "- `total_rooms`: Gesamtzahl der Räume eines Bezirks, Werte zwischen 2 und 39320\n",
    "- `total_bedrooms`: Gesamtzahl der Schlafzimmer eines Bezirks, Werte zwischen 1 und 6445\n",
    "- `population`: Einwohnerzahl eines Bezirks, Werte zwischen 3 und 35682\n",
    "- `households`: Gesamtzahl der Haushälte eines Bezirks, Werte zwischen 1 und 6082\n",
    "- `median_income`: Median des Einkommens der Einwohner, Werte zwischen 0.5 und 15\n",
    "- `median_house_value`: Median des Geldwertes der Häuser, Werte zwischen 15000 und 500 001 Dollar.\n",
    "\n",
    "Dabei fällt besonders der Wertebereich von `median_income` auf. Dies ist wahrscheinlich eine angepasste Skala und kein Einkommen in Dollar.\n",
    "\n",
    "Wenn wir noch einmal die Beschreibung eines Bezirks anschauen, dann sehen wir, dass in diesem Datensatz\n",
    "einige Ausreißer im Hinblick auf `population` vorliegen könnten. Denn ein Bezirk sollte hier zwischen 600 und 3000 Menschen umfassen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Fehlende Werte\n",
    "\n",
    "Der Datensatz enthält keine fehlenden Werte, wie wir in der `pd.info` Methode sehen können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Die Verteilung der Daten\n",
    "\n",
    "Nun schauen wir uns einige univariate und bivariate Plots der metrischen Merkmale an, um ein Gefühl für die Daten zu bekommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X.hist(figsize=(20, 15), bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Hier sehen wir, dass die vier Merkmale `total_rooms`, `total_bedrooms`, `population` und `households` eine relativ hohe\n",
    "Schiefe aufweisen.\n",
    "Ebenso hat `median_house_value` bei circa 500 000 eine hohe Dichte. Dies könnte dadurch begründet sein,\n",
    "dass der Wert 500 000 als obere Grenze benutzt wurde.\n",
    "\n",
    "Bevor wir uns also bivariate Plots ansehen, werden wir mittels LocalOutlierFactor (LOF) versuchen, einige Ausreißer zu eliminieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = LocalOutlierFactor(n_neighbors=35).fit_predict(X)\n",
    "outliers = X[labels == -1]\n",
    "X = X[labels == 1]\n",
    "\n",
    "print(f\"Anzahl an mittels LOF als Ausreißer identifizierte Bezirke: {outliers.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wir können, sehen, dass der maximale Wert von `population` nun deutlich niedriger ist. Dennoch gibt es Bezirke mit sehr geringen Einwohnerzahlen (Minimum 3 Einwohner).\n",
    "\n",
    "Schauen wir uns nun einige bivariate Plots genauer an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(X, diag_kind=\"kde\", kind=\"scatter\", plot_kws={\"alpha\": 0.3})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "group1 = [\"longitude\", \"latitude\"]\n",
    "group2 = [\"total_rooms\", \"total_bedrooms\", \"population\", \"households\"]\n",
    "group3 = [\"median_income\", \"median_house_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(X[group1], diag_kind=\"kde\", kind=\"scatter\", plot_kws={\"alpha\": 0.3}, size=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(X[group2], diag_kind=\"kde\", kind=\"scatter\", plot_kws={\"alpha\": 0.3}, size=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(X[group3], diag_kind=\"kde\", kind=\"scatter\", plot_kws={\"alpha\": 0.3}, size=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In diesem Pairplot sind univariate Plots auf der Hauptdiagonalen und bivariate Plots (hier Scatter-Plots) auf den nicht-diagonalen Elementen.\n",
    "Es fällt auf, dass die Merkmale total_rooms, total_bedrooms, population und households hoch miteinander korrelieren. Dies ist jedoch\n",
    "unter Beachtung der Bedeutung der Merkmale nicht überraschend, da eine hohe Anzahl an Menschen im Bezirk schließlich bedeuten muss, dass mehr\n",
    "Räume existieren und insgesamt die Zahl der Haushälte wohl höher sein muss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "sc = ax.scatter(x=\"longitude\", y=\"latitude\", c=\"median_house_value\", cmap=\"viridis\", data=X, alpha=0.5)\n",
    "plt.colorbar(sc, label=\"median_house_value\")\n",
    "\n",
    "cities = [\"Los Angeles\", \"San Francisco\"]\n",
    "xys = [(-118.243683, 34.052235), (-122.431297, 37.773972)]\n",
    "xys_text = [(-121, 33.5), (-123, 35.5)]\n",
    "for city, xy, xytext in zip(cities, xys, xys_text):\n",
    "    ax.annotate(city, xy=xy,  xycoords='data',\n",
    "            xytext=xytext,\n",
    "            arrowprops=dict(facecolor='red', shrink=0.05),\n",
    "            horizontalalignment='right', verticalalignment='top',\n",
    "            )\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "ax.set_xlabel(\"Längengrad\")\n",
    "ax.set_ylabel(\"Breitengrad\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Die Bezirke mit sehr teuren Häusern liegen am unteren Rand, also an der Küste. Zwei große Städte sind im Bild mit einem Pfeil markiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faktoranalyse Schritt 1: Geeignetheit der Daten untersuchen\n",
    "\n",
    "Bevor wir mit der eigentlichen Faktoranalyse starten, müssen wir die Geeignetheit der Daten überprüfen.\n",
    "Dafür benutzen wir das Kaiser-Meyer-Olkin-Kriterium (KMO-Kriterium) für den kompletten Datensatz und das\n",
    "dazu verwandte Measure of sampling adequacy (MSA) für jedes einzelne Merkmal.\n",
    "\n",
    "Generell wollen wir, dass der KMO-Wert über 0.5 ist und der MSA-Wert für jede Variable ebenfalls 0.5 nicht\n",
    "unterschreitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "msa_values, kmo = calculate_kmo(X)\n",
    "print(f\"Der KMO-Wert beträgt {kmo:.4f}\\n\")\n",
    "msa_df = pd.DataFrame(msa_values.reshape(-1, 1), index=X.columns, columns=[\"MSA\"])\n",
    "print(msa_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der KMO-Wert ist über 0.6, was auf eine akzeptable Qualität hinweist. Dies ist jedoch kein idealer Wert.\n",
    "Außerdem ist der MSA-Wert für 4 Variablen unter 0.5, jedoch ist der Wert für die anderen Merkmale gut.\n",
    "\n",
    "Jetzt könnte man beispielweise die Merkmale mit einem MSA-Wert unter 0.5 entfernen. Für dieses Beispiel\n",
    "werden wir allerdings mit allen Variablen fortfahren.\n",
    "\n",
    "Man sollte sich zudem noch die Korrelationsmatrix direkt anschauen. Dies tun wir im Folgenden mit einer\n",
    "Heatmap, da sie sich sehr gut als visuelle Repräsentation eignet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "corr = X.corr().round(2)\n",
    "hm = sns.heatmap(data=corr, vmax=1, vmin=-1, cmap=\"RdBu_r\", annot=True)\n",
    "hm.set_xticklabels(X.columns, rotation=45)\n",
    "hm.set_yticklabels(X.columns)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Hier sieht man, dass es mehrere Gruppen von hoch korrelierten Merkmalen gibt. Wie wir schon im Pairplot gesehen haben,\n",
    "sind das die vier Merkmale in der Mitte, sowie `housing_median_age` mit einer leicht negativen Korrelation zu diesen vier Merkmalen.\n",
    "Ebenso sind `Longitude` und `Latitude` negativ miteinander korreliert. Die Merkmale `median_income` und `median_house_value` sind positiv miteinander korreliert.\n",
    "\n",
    "Dies deutet schon darauf hin, dass eine 3-Faktorlösung wahrscheinlich eine gute Wahl von k sein könnte. Im Folgenden werden dies genauer betrachten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Faktoranalyse Schritt 2: Wahl der Faktorzahl $k$\n",
    "\n",
    "Um diese Frage zu beantworten, werden wir zunächst alle Faktoren mit der Hauptkomponentenmethode (Principal Component, PC)\n",
    "extrahieren und die Eigenwerte der Faktoren mithilfe eines 'Scree Plots' betrachten.\n",
    "\n",
    "Dann können wir die Faktoren behalten, die einen Eigenwert größer Eins (Kaiser-Kriterium) haben, oder anhand eines 'Knicks'\n",
    "im Plot eine geeignete Faktorzahl erkennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fa = FactorAnalysis(n_factors=X.shape[1], method=\"pc\").fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13, 8))\n",
    "scree_plot(fa.eigenvalues_, ax)\n",
    "ax.set_xlabel(\"Faktor\")\n",
    "ax.set_ylabel(\"Eigenwert\")\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier können wir sehen, dass die ersten drei Faktoren einen Eigenwert\n",
    "größer als Eins haben. Dies macht im Hinblick auf die Korrelationsmatrix,\n",
    "die wir vorhin gesehen haben, wegen den drei 'Boxen' auch Sinn. Nach\n",
    "dem Kaiser-Kriterium sollten wir also ein 3-Faktor-Modell benutzen.\n",
    "\n",
    "Der vierte Faktor ist jedoch nur minimal unter dem Eigenwert Eins, weshalb\n",
    "man diesen auch nicht direkt ausschließen sollte. Ein 'Knick' wäre bei\n",
    "$k = 5$ erkennbar.\n",
    "Wir werden also $k \\in [3, 4, 5]$ ausprobieren und den 'Besten' auswählen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Faktoranalyse Schritt 3: Extrahieren der Faktoren\n",
    "Jetzt führen wir die eigentliche Faktorextraktion durch.\n",
    "\n",
    "Dafür werden wir drei unterschiedliche Extraktionsmethoden miteinander vergleichen:\n",
    " - Hauptkomponentenmethode (engl. Principal Components (PC) Method)\n",
    " - Hauptachsen-Faktorisierung (engl. Principal Axis Factoring (PAF))\n",
    " - Iterierte Hauptachsen-Faktorisierung (engl. Iterated Principal Axis Factoring (Iterated PAF))\n",
    "\n",
    "Dabei ist die letzte Variante wohl die am häufigsten eingesetzte Methode (unter diesen drei)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "methods = [\n",
    "    (\"PC\", FactorAnalysis(method=\"pc\")),\n",
    "    (\"Nicht-iterierte PAF\", FactorAnalysis(method=\"paf\", max_iter=1)),\n",
    "    (\"Iterierte PAF\", FactorAnalysis(method=\"paf\", max_iter=50))\n",
    "]\n",
    "for n_factors in range(3, 6):\n",
    "    figsize = (10 + (1+n_factors)//2, 8)\n",
    "    # this convenience method accepts unfitted factor analysis instances\n",
    "    # and fits them for us. With the fa_params dict we can easily specify\n",
    "    # the arguments which are shared across all instances.\n",
    "    create_loadings_heatmaps(X, methods, figsize, fa_params={\"n_factors\": n_factors})\n",
    "    plt.gcf().suptitle(f\"Ladungsmatrizen eines {n_factors}-Faktor-Modells\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Hier sehen wir in jeder Zeile die Ladungsmatrizen der drei unterschiedlichen Methoden als Heatmap dargestellt.\n",
    "Wir stellen fest, dass die 3-Faktorlösung tatsächlich im Hinblick auf eine einfache Struktur eine gute Lösung darstellt.\n",
    "Die 4-Faktorlösung könnte jedoch auch noch eine valide Lösung sein. Lediglich die 5-Faktorlösung ist problematisch,\n",
    "da kein Merkmal hoch (absoluter Wert größer 0.4) auf den fünften Faktor lädt.\n",
    "\n",
    "Ein Problem ist jedoch, dass das Merkmal `housing_median_age` nur bei der PC-Methode sehr hoch auf den vierten Faktor lädt\n",
    "und bei einer 3-Faktorlösung nur eine moderate Ladung auf den ersten Faktor hat.\n",
    "Dies deutet auf eine hohe spezifische Varianz hin, d.h. die Faktoren sind nicht gut in der Lage, die Varianz dieses Merkmals\n",
    "zu erklären.\n",
    "\n",
    "Wir werden also die 3-Faktorlösung genauer betrachten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fa_params = {\"n_factors\": 3}\n",
    "\n",
    "axes = create_loadings_heatmaps(X, methods, figsize=(10, 9), fa_params=fa_params, annotate=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wir können sehen, dass bei der PC-Methode die Ladungen generell höher ausfallen und dass der zweite Faktor ein unterschiedliches\n",
    "Vorzeichen besitzt, im Gegensatz zu den anderen beiden Methoden.\n",
    "\n",
    "Die iterierte und nicht-iterierte PAF-Methode sind sehr ähnlich zueinander. Jedoch ist die iterierte\n",
    "Variante oft in Hinblick auf die reproduzierte Korrelationsmatrix besser. Dies können wir anhand des\n",
    "*root mean squared error* (RMSE) untersuchen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for method, fa in methods:\n",
    "    print(f\"RMSE von {method}: {fa.get_rmse():.4f}\")\n",
    "    rmse = fa.get_rmse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Der root mean squared error of residuals (RMSE) ist bei der iterierten PAF-Methode am geringsten,\n",
    "gefolgt von der nicht-iterativen Variante und der Hauptkomponentenmethode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Da das Merkmal `housing_median_age` eine sehr hohe spezifische Varianz (geringe Kommunalität) aufweist\n",
    "können wir auch ein 3-Faktor-Modell ohne diesem Merkmal anschauen.\n",
    "Dieses kann den RMSE um knapp 44% reduzieren (im Vergleich sind die iterierten PAF-Methoden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_without_age = X.drop(columns=\"housing_median_age\", axis=1)\n",
    "fa_without_age = FactorAnalysis(n_factors=3).fit(X_without_age)\n",
    "perc = 1 - fa_without_age.get_rmse() / rmse\n",
    "print(f\"Der RMSE konnte durch entfernen des Merkmals um {perc:.2%} reduziert werden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "Den Unterschied zwischen den Methoden im RMSE können wir auch noch grafisch analysieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(12, 6))\n",
    "fitted_methods = [\n",
    "    (\"PC\", FactorAnalysis(method=\"pc\", n_factors=3).fit(X)),\n",
    "    (\"Iterierte PAF\", FactorAnalysis(method=\"paf\", n_factors=3, max_iter=50).fit(X))\n",
    "]\n",
    "for ax, (method, fa) in zip(axes, fitted_methods):\n",
    "    R = fa.corr_\n",
    "    R_hat = fa.get_reprod_corr()\n",
    "    abs_residuals = np.abs(R - R_hat)\n",
    "    mask = np.triu(np.ones_like(R))\n",
    "    ax.set_title(f\"{method} (RMSE = {fa.get_rmse():.4f})\", fontsize=11)\n",
    "    s = sns.heatmap(abs_residuals.round(2), cmap=\"BuGn\", ax=ax, cbar=False, annot=True, square=True, mask=mask)\n",
    "    s.set_xticklabels(range(1, 10))\n",
    "    s.set_yticklabels(range(1, 10), rotation=360)\n",
    "fig.suptitle(\"Residualmatrizen von zwei Extraktionsmethoden mit k=3\")\n",
    "#fig.set_size_inches(w=TEXT_WIDTH, h=4.5)\n",
    "fig.tight_layout()\n",
    "#plt.savefig(\"./plots/cal_housing_residual_mtx.pgf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Zusammenfassung der iterierten PAF-Methode\n",
    "methods[2][1].print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In der Zusammenfassung können wir neben den Ladungen auch die Kommunalitäten und spezifischen Varianzen,\n",
    " sowie Eigenwerte und den Anteil erklärter Varianz durch die Faktoren betrachten .\n",
    "\n",
    "\n",
    "Wir können sehen, dass die spezifischen Varianze von 'housing_median_age' mit einem Wert zwischen 0.90 sehr hoch ist.\n",
    "Das bedeutet, dass die Faktoren die Varianz dieses Merkmals gemeinsam nicht besonders gut erklären können. Dies spiegelt sich ebenfalls in den\n",
    "sehr geringen Ladungen auf die drei Faktoren wider.\n",
    "Die spezifischen Varianzen bei den restlichen Merkmalen sind jedoch sehr niedrig,\n",
    "was ein gutes Zeichen für die Qualität der Faktorlösung ist.\n",
    "\n",
    "Alle Merkmale, bis auf des eben angesprochenen Merkmals können eindeutig einem Faktor durch jeweils die betraglich\n",
    "größte Ladung zugeordnet werden. Dies ist nicht immer der Fall, sodass eine Faktorrotation für eine leichtere Interpretation\n",
    "sorgen könnte. Hier ist jedoch auch ohne Rotation eine Interpretation gut möglich. Wir werden im nächsten Schritt trotzdem\n",
    "beispielhaft die mit der Varimax-Methode rotierten Faktorladungen ansehen.\n",
    "\n",
    "Bevor wir das tun, werden wir noch die verschiedenen initialen Schätzungen der Kommunalitäten in der (iterierten) PAF-Methode vergleichen.\n",
    "Interessant könnte dabei sein, ob die Wahl der initialen Schätzung einen Einfluss auf die finalen Kommunalitäten hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "paf_comparison_methods = [\n",
    "    (\"Nicht-iterierte PAF\", FactorAnalysis(method=\"paf\", max_iter=1)),\n",
    "    (\"PAF mit max_iter=3\", FactorAnalysis(method=\"paf\", max_iter=3)),\n",
    "    (\"Iterierte PAF\", FactorAnalysis(method=\"paf\", max_iter=50)),\n",
    "]\n",
    "figsize = (8, 6)\n",
    "initial_communality_estimates = {\n",
    "    \"smc\": \"Quadrierte multiple Korrelationen (SMC)\",\n",
    "    \"mac\": \"Maximale absolute Korrelationen (MAC)\",\n",
    "    \"ones\": \"Einsen\"\n",
    "}\n",
    "for init_comm in initial_communality_estimates:\n",
    "    print(f\"Initiale Schätzung: {initial_communality_estimates[init_comm]}\")\n",
    "    create_loadings_heatmaps(X, paf_comparison_methods, figsize, fa_params={\"n_factors\": 3, \"initial_comm\" : init_comm})\n",
    "    plt.show()\n",
    "    print(f\"Iterierte PAF hat {paf_comparison_methods[2][1].n_iter_} Iterationen benötigt.\")\n",
    "    for method, fa in paf_comparison_methods:\n",
    "        print(f\"RMSE von {method}: {fa.get_rmse():.4f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wir können sehen, dass nur geringe Unterschiede zwischen den unterschiedlichen initialen Schätzungen\n",
    "in den Ladungen feststellbar sind. Nur in der nicht-iterierten Variante der PAF-Methode können wir einige\n",
    "Unterschiede, vor allem im zweiten Faktor feststellen. Beispielsweise hat der zweite Faktor ein unterschiedliches\n",
    "Vorzeichen, jedoch nur wenn Einsen als Kommunalitätsschätzung benutzt werden.\n",
    "\n",
    "Wir stellen fest, dass die iterierte Variante jedoch eine unterschiedliche Anzahl an Iterationen benötigt, bis\n",
    "das Konvergenzkriterium erreicht wird. Am Langsamsten ist es mm Falle von Einsen (10 Iterationen) und am schnellsten ist es\n",
    "bei den maximalen absoluten Korrelationen (MAC) (nur 3 Iterationen). Ist das Konvergenzkriterium erfüllt, sind die Ladungen jedoch\n",
    "bei allen drei initialen Schätzungen weitestgehend identisch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Faktoranalyse Schritt 4: Faktorrotation und -interpretation\n",
    "Jetzt rotieren wir die Ladungen mit der Varimax-Methode und versuchen, die Faktoren zu interpretieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "methods = [\n",
    "    (\"Unrotiert\", FactorAnalysis(method=\"paf\", rotation=None)),\n",
    "    (\"Varimax-Rotation\", FactorAnalysis(method=\"paf\", rotation=\"varimax\"))\n",
    "]\n",
    "fa_params = {\"n_factors\": 3}\n",
    "fig = create_loadings_heatmaps(X_without_age, methods, fa_params=fa_params)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Faktoranalyse Schritt 5: Die Faktorwerte bestimmen\n",
    "\n",
    "Als letzten Schritt können wir noch einen Blick auf die geschätzten Faktorwerte\n",
    "werfen. Wie hätte als der Bezirk $i$ die drei oben beschriebenen Faktoren bewertet?\n",
    "\n",
    "Da die Daten standardisiert wurden, sind die Faktorwerte auch (fast) standardisiert.\n",
    "Der Mittelwert liegt bei Null, jedoch ist die Varianz der Faktorwerte nicht exakt 1.\n",
    "Daher geben die Faktorwerte an, wie weit weg vom Mittelwert ein bestimmter Faktorwert\n",
    "$f_{ij}$ des $i$-ten Bezirks für Faktor $j$ liegt.\n",
    "Die hier benutzte Methode zur Schätzung der Faktorwerte ist die *Regressionsmethode*\n",
    "welche eine multivariate lineare Regression benutzt, um die Faktorwerte\n",
    "zu schätzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scores = FactorAnalysis(n_factors=3).fit_transform(X_without_age)\n",
    "scores = pd.DataFrame(scores, columns=[\"Größe\", \"Standort\", \"Wohlstand\"])\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scores.std(axis=0) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Benutzt man jedoch die Hauptkomponentenmethode, so weisen die Faktorwerte eine\n",
    "Standardabweichung von Eins auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scores = FactorAnalysis(method=\"pc\", n_factors=3).fit_transform(X)\n",
    "scores.std(axis=0) ** 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
